{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "import setup_path\n",
    "from src.preprocess import preprocess_data\n",
    "from src.segment_data import segment_data\n",
    "from src.model import define_model\n",
    "\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "processed_df, _ = preprocess_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Function Definitions ---\n",
    "\n",
    "def initialize_metadata(df):\n",
    "\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    if 'Premium Amount' in categorical_features:\n",
    "        categorical_features.remove('Premium Amount')\n",
    "    \n",
    "    category_mappings = {col: sorted(df[col].unique()) for col in categorical_features}\n",
    "\n",
    "    return categorical_features, category_mappings\n",
    "\n",
    "\n",
    "def create_segment_pipeline(segment_name, config, categorical_features, category_mappings, numeric_features):\n",
    "\n",
    "    categorical_transformer = OneHotEncoder(\n",
    "        categories=[category_mappings[col] for col in categorical_features],\n",
    "        sparse_output=False,\n",
    "        handle_unknown='ignore'\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        sparse_threshold=0\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', config['model'])\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "\n",
    "    return {\n",
    "        'r2_score': r2_score(y_true, y_pred),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "        'median_ae': np.median(np.abs(y_true - y_pred))\n",
    "    }\n",
    "\n",
    "\n",
    "def train_segment_model(X_seg, y_seg, segment_name, config, categorical_features, category_mappings):\n",
    "\n",
    "    numeric_features = X_seg.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    if 'Premium Amount' in numeric_features:\n",
    "        numeric_features.remove('Premium Amount')\n",
    "\n",
    "    pipeline = create_segment_pipeline(segment_name, config, categorical_features, category_mappings, numeric_features)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_seg, y_seg, test_size=0.2, random_state=42)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = pipeline.predict(X_train)\n",
    "    test_pred = pipeline.predict(X_test)\n",
    "\n",
    "    train_metrics = evaluate_predictions(y_train, train_pred)\n",
    "    test_metrics = evaluate_predictions(y_test, test_pred)\n",
    "\n",
    "    cv_scores = cross_val_score(\n",
    "        pipeline, X_seg, y_seg, cv=5,\n",
    "        scoring=make_scorer(r2_score), n_jobs=-1\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'model': pipeline,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_scores': cv_scores,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'test_data': (X_test, y_test)\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_feature_importance(model, categorical_features):\n",
    "\n",
    "    feature_names = []\n",
    "\n",
    "    num_features = model.named_steps['preprocessor'].transformers_[0][2]\n",
    "    feature_names.extend(num_features)\n",
    "\n",
    "    cat_features = model.named_steps['preprocessor'].transformers_[1][2]\n",
    "\n",
    "    if len(cat_features) > 0:\n",
    "        encoder = model.named_steps['preprocessor'].named_transformers_['cat']\n",
    "        if hasattr(encoder, 'get_feature_names_out'):\n",
    "            encoded = encoder.get_feature_names_out(cat_features)\n",
    "            feature_names.extend(encoded)\n",
    "\n",
    "    if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "        importances = model.named_steps['regressor'].feature_importances_\n",
    "    else:\n",
    "        importances = np.mean([\n",
    "            est.feature_importances_ \n",
    "            for name, est in model.named_steps['regressor'].estimators_\n",
    "            if hasattr(est, 'feature_importances_')\n",
    "        ], axis=0)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "\n",
    "def train_all_segments(df, segments, segment_configs):\n",
    "\n",
    "    categorical_features, category_mappings = initialize_metadata(df)\n",
    "    feature_cols = [col for col in df.columns if col != 'Premium Amount']\n",
    "    target_col = 'Premium Amount'\n",
    "\n",
    "    segment_results = {}\n",
    "\n",
    "    for name, mask in segments.items():\n",
    "\n",
    "        print(f\"\\nProcessing {name} segment...\")\n",
    "\n",
    "        X_seg = df[feature_cols][mask]\n",
    "        y_seg = df[target_col][mask]\n",
    "\n",
    "        print(f\"Segment Length {len(X_seg)}...\")\n",
    "\n",
    "        if len(X_seg) >= 100:\n",
    "            config = segment_configs.get(name, segment_configs['default'])\n",
    "\n",
    "            result = train_segment_model(\n",
    "                X_seg, y_seg, name, config, categorical_features, category_mappings\n",
    "            )\n",
    "            segment_results[name] = result\n",
    "\n",
    "            print(f\"Train R2: {result['train_metrics']['r2_score']:.4f}\")\n",
    "            print(f\"Test R2: {result['test_metrics']['r2_score']:.4f}\")\n",
    "            print(f\"MAE: {result['test_metrics']['mae']:.2f}\")\n",
    "            print(f\"Median AE: {result['test_metrics']['median_ae']:.2f}\")\n",
    "            print(f\"MAPE: {result['test_metrics']['mape']:.2f}%\")\n",
    "            print(f\"RMSE: {result['test_metrics']['rmse']:.2f}\")\n",
    "            print(f\"CV R2: {result['cv_mean']:.4f} (+/- {result['cv_std'] * 2:.4f})\")\n",
    "\n",
    "    performance_df = pd.DataFrame.from_dict({\n",
    "        name: {\n",
    "            'segment_size': len(df[segments[name]]),\n",
    "            'train_r2': res['train_metrics']['r2_score'],\n",
    "            'test_r2': res['test_metrics']['r2_score'],\n",
    "            'cv_mean_r2': res['cv_mean'],\n",
    "            'cv_std_r2': res['cv_std'],\n",
    "            'mae': res['test_metrics']['mae'],\n",
    "            'mape': res['test_metrics']['mape']\n",
    "        }\n",
    "        for name, res in segment_results.items()\n",
    "    }, orient='index')\n",
    "\n",
    "    print(\"\\nSegment Performance Summary:\")\n",
    "    print(performance_df.sort_values('test_r2', ascending=False))\n",
    "\n",
    "    return segment_results, performance_df\n",
    "\n",
    "\n",
    "def get_segment_predictions(segment_results, segment_name, X_new):\n",
    "\n",
    "    if segment_name not in segment_results:\n",
    "        raise ValueError(f\"No model found for segment: {segment_name}\")\n",
    "\n",
    "    return segment_results[segment_name]['model'].predict(X_new)\n",
    "\n",
    "\n",
    "def get_feature_importance(segment_results, segment_name, categorical_features):\n",
    "\n",
    "    if segment_name not in segment_results:\n",
    "        raise ValueError(f\"No model found for segment: {segment_name}\")\n",
    "\n",
    "    return analyze_feature_importance(segment_results[segment_name]['model'], categorical_features)\n",
    "\n",
    "\n",
    "def get_segment_metrics(segment_results, segment_name):\n",
    "\n",
    "    if segment_name not in segment_results:\n",
    "        raise ValueError(f\"No results found for segment: {segment_name}\")\n",
    "    res = segment_results[segment_name]\n",
    "\n",
    "    return {\n",
    "        'train_metrics': res['train_metrics'],\n",
    "        'test_metrics': res['test_metrics'],\n",
    "        'cv_scores': res['cv_scores'],\n",
    "        'cv_mean': res['cv_mean'],\n",
    "        'cv_std': res['cv_std']\n",
    "    }\n",
    "\n",
    "\n",
    "categorical_features, category_mappings = initialize_metadata(processed_df)\n",
    "\n",
    "segments = segment_data(processed_df)\n",
    "segment_configs = define_model()\n",
    "\n",
    "segment_results, performance_df = train_all_segments(processed_df, segments, segment_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_test_data(df, segment_function):\n",
    "    \"\"\"Segment test data using the provided segmentation logic.\"\"\"\n",
    "    segments = segment_function(df)\n",
    "    return {key: df[mask] for key, mask in segments.items()}\n",
    "\n",
    "\n",
    "def predict_and_export(test_df, test_ids, segment_results, segment_function, categorical_features, output_file='predicted_premiums.csv'):\n",
    "    \"\"\"\n",
    "    Predict and export results for test data using the trained models.\n",
    "\n",
    "    Parameters:\n",
    "        test_df (pd.DataFrame): The processed test data\n",
    "        test_ids (pd.Series): Corresponding IDs for tracking\n",
    "        segment_results (dict): Trained models by segment\n",
    "        segment_function (callable): Function to segment the data\n",
    "        categorical_features (list): List of categorical features\n",
    "        output_file (str): File name to export predictions\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "\n",
    "    # Segment test data\n",
    "    segments = segment_test_data(test_df, segment_function)\n",
    "\n",
    "    for segment_name, segment_df in segments.items():\n",
    "        if not segment_df.empty:\n",
    "            try:\n",
    "                model = segment_results.get(segment_name)\n",
    "                if model is None:\n",
    "                    print(f\"No trained model for segment: {segment_name}\")\n",
    "                    continue\n",
    "\n",
    "                segment_ids = test_ids.loc[segment_df.index]\n",
    "                segment_preds = model['model'].predict(segment_df)\n",
    "\n",
    "                predictions.extend(zip(segment_ids, segment_preds))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error in segment {segment_name}: {e}\")\n",
    "\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['id', 'Premium Amount'])\n",
    "\n",
    "    # Average over duplicate IDs\n",
    "    predictions_df = predictions_df.groupby('id', as_index=False)['Premium Amount'].mean()\n",
    "\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions exported to {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
