{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment Distribution:\n",
      "High_Value_Property: 59,844 (5.0%)\n",
      "Low_Risk_Premium: 153,743 (12.8%)\n",
      "Healthy_Professional: 234,873 (19.6%)\n",
      "Family_Premium: 128,426 (10.7%)\n",
      "Basic_Coverage: 278,995 (23.2%)\n",
      "Default_Segment: 591,853 (49.3%)\n",
      "\n",
      "Total records: 1,200,000\n",
      "Total assigned: 1,447,734\n",
      "Records per segment on average: 241,289.0\n",
      "\n",
      "Processing High_Value_Property segment...\n",
      "\n",
      "Segment Length 59844...\n",
      "Train R2: 0.0293\n",
      "Test R2: 0.0226\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 712.71\n",
      "Median Absolute Error: 593.72\n",
      "Mean % Error: 337.67%\n",
      "RMSE: 917.61\n",
      "CV Mean R2: 0.0218 (+/- 0.0023)\n",
      "\n",
      "Processing Low_Risk_Premium segment...\n",
      "\n",
      "Segment Length 153743...\n",
      "Train R2: 0.0198\n",
      "Test R2: 0.0202\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 676.79\n",
      "Median Absolute Error: 548.09\n",
      "Mean % Error: 311.28%\n",
      "RMSE: 876.70\n",
      "CV Mean R2: 0.0195 (+/- 0.0017)\n",
      "\n",
      "Processing Healthy_Professional segment...\n",
      "\n",
      "Segment Length 234873...\n",
      "Train R2: 0.0131\n",
      "Test R2: 0.0099\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 687.66\n",
      "Median Absolute Error: 573.00\n",
      "Mean % Error: 302.99%\n",
      "RMSE: 887.37\n",
      "CV Mean R2: 0.0098 (+/- 0.0011)\n",
      "\n",
      "Processing Family_Premium segment...\n",
      "\n",
      "Segment Length 128426...\n",
      "Train R2: 0.0140\n",
      "Test R2: 0.0123\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 674.92\n",
      "Median Absolute Error: 559.52\n",
      "Mean % Error: 312.52%\n",
      "RMSE: 868.65\n",
      "CV Mean R2: 0.0122 (+/- 0.0016)\n",
      "\n",
      "Processing Basic_Coverage segment...\n",
      "\n",
      "Segment Length 278995...\n",
      "Train R2: 0.0060\n",
      "Test R2: 0.0040\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 676.86\n",
      "Median Absolute Error: 560.80\n",
      "Mean % Error: 316.80%\n",
      "RMSE: 866.88\n",
      "CV Mean R2: 0.0040 (+/- 0.0006)\n",
      "\n",
      "Processing Default_Segment segment...\n",
      "\n",
      "Segment Length 591853...\n",
      "Train R2: 0.0094\n",
      "Test R2: 0.0080\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 651.57\n",
      "Median Absolute Error: 532.07\n",
      "Mean % Error: 299.79%\n",
      "RMSE: 843.54\n",
      "CV Mean R2: 0.0083 (+/- 0.0005)\n",
      "\n",
      "Segment Performance Summary:\n",
      "                      segment_size  train_r2   test_r2  cv_mean_r2  cv_std_r2  \\\n",
      "High_Value_Property         591853  0.029320  0.022558    0.021764   0.001171   \n",
      "Low_Risk_Premium            591853  0.019799  0.020179    0.019547   0.000873   \n",
      "Family_Premium              591853  0.013989  0.012289    0.012240   0.000814   \n",
      "Healthy_Professional        591853  0.013142  0.009921    0.009837   0.000556   \n",
      "Default_Segment             591853  0.009407  0.008003    0.008324   0.000232   \n",
      "Basic_Coverage              591853  0.006022  0.004049    0.004016   0.000302   \n",
      "\n",
      "                             mae        mape  \n",
      "High_Value_Property   712.706641  337.673554  \n",
      "Low_Risk_Premium      676.791003  311.280617  \n",
      "Family_Premium        674.922109  312.524007  \n",
      "Healthy_Professional  687.661361  302.987062  \n",
      "Default_Segment       651.565372  299.794907  \n",
      "Basic_Coverage        676.860171  316.800678  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from preprocess import preprocess_data\n",
    "\n",
    "def define_segments(df):\n",
    "    \"\"\"Define customer segments with fuzzy boundaries and consideration of data quality.\"\"\"\n",
    "    \n",
    "    # Calculate reliability scores based on imputed values\n",
    "    reliability_score = 1.0\n",
    "    for col in ['Occupation_is_missing', 'Previous Claims_is_missing', 'Credit Score_is_missing']:\n",
    "        if col in df.columns:\n",
    "            reliability_score -= df[col] * 0.1\n",
    "    \n",
    "    segments = {\n",
    "        'High_Value_Property': (\n",
    "            (df['Property Type'].isin(['House', 'Condo'])) &\n",
    "            (df['Annual Income'] >= df['Annual Income'].quantile(0.55)) &\n",
    "            ((df['Policy Type'] == 'Premium') | \n",
    "             (df['Policy Type'] == 'Standard')) &\n",
    "            (df['Credit Score'] > df['Credit Score'].quantile(0.45)) &\n",
    "            (reliability_score >= 0.8)  # Only include highly reliable records\n",
    "        ),\n",
    "        \n",
    "        'Low_Risk_Premium': (\n",
    "            (df['Credit Score'] > df['Credit Score'].quantile(0.5)) &\n",
    "            (df['Health Score'] > df['Health Score'].quantile(0.5)) &\n",
    "            (df['Insurance Duration'] > 1) &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.4)) &\n",
    "            (reliability_score >= 0.7)\n",
    "        ),\n",
    "        \n",
    "        'Healthy_Professional': (\n",
    "            ((df['Age'] <= df['Age'].quantile(0.4)) |\n",
    "             (df['Exercise Frequency'].isin(['Daily', 'Weekly']))) &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.45)) &\n",
    "            (df['Health Score'] > df['Health Score'].quantile(0.5)) &\n",
    "            (reliability_score >= 0.7)\n",
    "        ),\n",
    "        \n",
    "        'Family_Premium': (\n",
    "            (df['Number of Dependents'] >= 1) &\n",
    "            (df['Location'].isin(['Suburban', 'Rural'])) &\n",
    "            (df['Marital Status'] == 'Married') &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.4)) &\n",
    "            (reliability_score >= 0.8)\n",
    "        ),\n",
    "        \n",
    "        'Basic_Coverage': (\n",
    "            ((df['Annual Income'] <= df['Annual Income'].quantile(0.35)) |\n",
    "             (df['Previous Claims'] >= 2) |\n",
    "             (df['Credit Score'] < df['Credit Score'].quantile(0.35))) &\n",
    "            (df['Policy Type'] == 'Basic')\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def define_model():\n",
    "    \"\"\"Define robust model configurations optimized for high-missing-data scenarios.\"\"\"\n",
    "    \n",
    "    # Base configurations\n",
    "    base_configs = {\n",
    "        # Conservative RandomForest for general use\n",
    "        'rf_robust': RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=6,                  # Reduced depth\n",
    "            min_samples_leaf=50,          # Increased to prevent overfitting\n",
    "            min_samples_split=100,        # Added to ensure robust splits\n",
    "            max_features='sqrt',\n",
    "            bootstrap=True,\n",
    "            oob_score=True,              # Enable out-of-bag scoring\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        # XGBoost with strong regularization\n",
    "        'xgb_conservative': XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,                  # Very shallow trees\n",
    "            learning_rate=0.01,           # Slower learning rate\n",
    "            subsample=0.7,                # Reduced sample size\n",
    "            colsample_bytree=0.7,         # Feature subsampling\n",
    "            min_child_weight=10,          # Increased to prevent overfitting\n",
    "            reg_alpha=1,                  # L1 regularization\n",
    "            reg_lambda=2,                 # L2 regularization\n",
    "            random_state=42\n",
    "        ),\n",
    "        \n",
    "        # Gradient Boosting with focus on robustness\n",
    "        'gbm_simple': GradientBoostingRegressor(\n",
    "            n_estimators=80,\n",
    "            max_depth=3,                  # Very shallow trees\n",
    "            learning_rate=0.01,           # Slower learning rate\n",
    "            subsample=0.7,                # Subsample for robustness\n",
    "            min_samples_leaf=50,          # Conservative leaf size\n",
    "            random_state=42\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Segment-specific configurations\n",
    "    model = {\n",
    "        'High_Value_Property': {\n",
    "            'model': base_configs['rf_robust'],\n",
    "            'description': 'Robust RF for high-value properties'\n",
    "        },\n",
    "        'Low_Risk_Premium': {\n",
    "            'model': base_configs['gbm_simple'],\n",
    "            'description': 'Simple GBM for low-risk segment'\n",
    "        },\n",
    "        'Healthy_Professional': {\n",
    "            'model': base_configs['rf_robust'],\n",
    "            'description': 'Robust RF for professional segment'\n",
    "        },\n",
    "        'Family_Premium': {\n",
    "            'model': base_configs['xgb_conservative'],\n",
    "            'description': 'Conservative XGBoost for family segment'\n",
    "        },\n",
    "        'Senior_Premium': {\n",
    "            'model': base_configs['gbm_simple'],\n",
    "            'description': 'Simple GBM for senior segment'\n",
    "        },\n",
    "        'Basic_Coverage': {\n",
    "            'model': base_configs['rf_robust'],\n",
    "            'description': 'Robust RF for basic coverage'\n",
    "        },\n",
    "        'default': {\n",
    "            'model': base_configs['rf_robust'],\n",
    "            'description': 'Default robust RF model'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model\n",
    "\n",
    "def segment_data(df):\n",
    "\n",
    "    segments = define_segments(df)\n",
    "\n",
    "    # Create a mask for all data assigned to a segment\n",
    "    assigned_mask = np.zeros(len(df), dtype=bool)\n",
    "    for mask in segments.values():\n",
    "        assigned_mask |= mask\n",
    "\n",
    "    # Create a default segment for unassigned data\n",
    "    segments['Default_Segment'] = ~assigned_mask\n",
    "\n",
    "    # Print distribution for debugging\n",
    "    total_records = len(df)\n",
    "    print(\"\\nSegment Distribution:\")\n",
    "    total_assigned = 0\n",
    "    for name, mask in segments.items():\n",
    "        segment_size = mask.sum()\n",
    "        total_assigned += segment_size\n",
    "        percentage = (segment_size / total_records) * 100\n",
    "        print(f\"{name}: {segment_size:,} ({percentage:.1f}%)\")\n",
    "\n",
    "    # Additional debug info\n",
    "    print(f\"\\nTotal records: {total_records:,}\")\n",
    "    print(f\"Total assigned: {total_assigned:,}\")\n",
    "    print(f\"Records per segment on average: {total_assigned/len(segments):,.1f}\")\n",
    "\n",
    "    return segments\n",
    "\n",
    "class InsuranceSegmentModel:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"Initialize the model with a DataFrame\"\"\"\n",
    "        self.df = df\n",
    "        self.processed_df = None\n",
    "        self.segment_results = {}\n",
    "        self.cv_results = {}\n",
    "\n",
    "        # Create standard category mappings at initialization\n",
    "        self.categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if 'Premium Amount' in self.categorical_features:\n",
    "            self.categorical_features.remove('Premium Amount')\n",
    "            \n",
    "        self.category_mappings = {\n",
    "            col: sorted(df[col].unique()) for col in self.categorical_features\n",
    "        }\n",
    "\n",
    "        # Segment data\n",
    "        self.segments = segment_data(df)\n",
    "\n",
    "        # Define model\n",
    "        self.segment_configs = define_model()\n",
    "\n",
    "    def create_segment_pipeline(self, segment_name):\n",
    "        \"\"\"Creates a pipeline specific to a segment\"\"\"\n",
    "        config = self.segment_configs.get(segment_name, self.segment_configs['default'])\n",
    "        \n",
    "        # Define feature groups\n",
    "        numeric_features = self.df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        if 'Premium Amount' in numeric_features:\n",
    "            numeric_features.remove('Premium Amount')\n",
    "                \n",
    "        # Only need encoder for categorical features\n",
    "        categorical_transformer = OneHotEncoder(\n",
    "            categories=[self.category_mappings[col] for col in self.categorical_features],\n",
    "            sparse_output=False,\n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "        \n",
    "        # Create preprocessor - numeric features pass through unchanged\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', numeric_features),\n",
    "                ('cat', categorical_transformer, self.categorical_features)\n",
    "            ],\n",
    "            sparse_threshold=0\n",
    "        )\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', config['model'])\n",
    "        ])\n",
    "        \n",
    "        return pipeline\n",
    "        \n",
    "    def evaluate_predictions(self, y_true, y_pred):\n",
    "        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "        return {\n",
    "            'r2_score': r2_score(y_true, y_pred),\n",
    "            'mae': mean_absolute_error(y_true, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "            'median_ae': np.median(np.abs(y_true - y_pred))\n",
    "        }\n",
    "    \n",
    "    def train_segment_model(self, X_seg, y_seg, segment_name):\n",
    "        \"\"\"Trains and evaluates a model for a specific customer segment\"\"\"\n",
    "        # Create pipeline\n",
    "        pipeline = self.create_segment_pipeline(segment_name)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_seg, y_seg, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        train_predictions = pipeline.predict(X_train)\n",
    "        test_predictions = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_metrics = self.evaluate_predictions(y_train, train_predictions)\n",
    "        test_metrics = self.evaluate_predictions(y_test, test_predictions)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline, X_seg, y_seg,\n",
    "            cv=5,\n",
    "            scoring=make_scorer(r2_score),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'model': pipeline,\n",
    "            'train_metrics': train_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'cv_scores': cv_scores,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_feature_importance(self, segment_name):\n",
    "        \"\"\"Analyzes feature importance for a specific segment\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            return None\n",
    "        \n",
    "        results = self.segment_results[segment_name]\n",
    "        model = results['model']\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = []\n",
    "        \n",
    "        # Get numeric feature names\n",
    "        num_features = model.named_steps['preprocessor'].transformers_[0][2]\n",
    "        feature_names.extend(num_features)\n",
    "        \n",
    "        # Get encoded categorical feature names\n",
    "        cat_features = model.named_steps['preprocessor'].transformers_[1][2]\n",
    "        if len(cat_features) > 0:\n",
    "            encoder = model.named_steps['preprocessor'].named_transformers_['cat']\n",
    "            if hasattr(encoder, 'get_feature_names_out'):\n",
    "                encoded_features = encoder.get_feature_names_out(cat_features)\n",
    "                feature_names.extend(encoded_features)\n",
    "        \n",
    "        # Get feature importances\n",
    "        if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "            importances = model.named_steps['regressor'].feature_importances_\n",
    "        else:\n",
    "            # For stacking regressor, use the average of base estimators\n",
    "            importances = np.mean([\n",
    "                est.feature_importances_ \n",
    "                for name, est in model.named_steps['regressor'].estimators_\n",
    "                if hasattr(est, 'feature_importances_')\n",
    "            ], axis=0)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def train_all_segments(self):\n",
    "        \"\"\"Trains models for all segments and generates performance summary\"\"\"\n",
    "        # Define feature and target columns\n",
    "        feature_cols = [col for col in self.df.columns if col != 'Premium Amount']\n",
    "        target_col = 'Premium Amount'\n",
    "        \n",
    "        # Use the original dataframe directly\n",
    "        self.processed_df = self.df.copy()\n",
    "        \n",
    "        # Train models for each segment\n",
    "        for name, mask in self.segments.items():\n",
    "            print(f\"\\nProcessing {name} segment...\")\n",
    "            X_seg = self.processed_df[feature_cols][mask]\n",
    "            y_seg = self.processed_df[target_col][mask]\n",
    "            print(f\"\\nSegment Length {len(X_seg)}...\")\n",
    "\n",
    "            if len(X_seg) >= 100:\n",
    "                results = self.train_segment_model(X_seg, y_seg, name)\n",
    "                self.segment_results[name] = results\n",
    "                \n",
    "                print(f\"Train R2: {results['train_metrics']['r2_score']:.4f}\")\n",
    "                print(f\"Test R2: {results['test_metrics']['r2_score']:.4f}\")\n",
    "                print(\"\\nPrediction Accuracy:\")\n",
    "                print(f\"Mean Absolute Error: {results['test_metrics']['mae']:.2f}\")\n",
    "                print(f\"Median Absolute Error: {results['test_metrics']['median_ae']:.2f}\")\n",
    "                print(f\"Mean % Error: {results['test_metrics']['mape']:.2f}%\")\n",
    "                print(f\"RMSE: {results['test_metrics']['rmse']:.2f}\")\n",
    "                print(f\"CV Mean R2: {results['cv_mean']:.4f} (+/- {results['cv_std']*2:.4f})\")\n",
    "        \n",
    "        # Create performance summary\n",
    "        performance_df = pd.DataFrame.from_dict(\n",
    "            {name: {\n",
    "                'segment_size': len(self.processed_df[mask]),\n",
    "                'train_r2': results['train_metrics']['r2_score'],\n",
    "                'test_r2': results['test_metrics']['r2_score'],\n",
    "                'cv_mean_r2': results['cv_mean'],\n",
    "                'cv_std_r2': results['cv_std'],\n",
    "                'mae': results['test_metrics']['mae'],\n",
    "                'mape': results['test_metrics']['mape']\n",
    "            } for name, results in self.segment_results.items()},\n",
    "            orient='index'\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSegment Performance Summary:\")\n",
    "        print(performance_df.sort_values('test_r2', ascending=False))\n",
    "                \n",
    "        return performance_df\n",
    "    \n",
    "    def get_segment_predictions(self, segment_name, X_new):\n",
    "        \"\"\"Get predictions for new data using a trained segment model\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            raise ValueError(f\"No trained model found for segment: {segment_name}\")\n",
    "        \n",
    "        model = self.segment_results[segment_name]['model']\n",
    "        return model.predict(X_new)\n",
    "    \n",
    "    def get_feature_importance(self, segment_name):\n",
    "        \"\"\"Get feature importance analysis for a specific segment\"\"\"\n",
    "        return self.analyze_feature_importance(segment_name)\n",
    "    \n",
    "    def get_segment_metrics(self, segment_name):\n",
    "        \"\"\"Get detailed performance metrics for a specific segment\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            raise ValueError(f\"No results found for segment: {segment_name}\")\n",
    "        \n",
    "        results = self.segment_results[segment_name]\n",
    "        return {\n",
    "            'train_metrics': results['train_metrics'],\n",
    "            'test_metrics': results['test_metrics'],\n",
    "            'cv_scores': results['cv_scores'],\n",
    "            'cv_mean': results['cv_mean'],\n",
    "            'cv_std': results['cv_std']\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv('train.csv')\n",
    "    processed_df, _ = preprocess_data(train)\n",
    "    insurance_model = InsuranceSegmentModel(processed_df)\n",
    "    performance_summary = insurance_model.train_all_segments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segment Distribution:\n",
      "High_Value_Property: 39,416 (4.9%)\n",
      "Low_Risk_Premium: 102,125 (12.8%)\n",
      "Healthy_Professional: 154,566 (19.3%)\n",
      "Family_Premium: 85,681 (10.7%)\n",
      "Basic_Coverage: 186,554 (23.3%)\n",
      "Default_Segment: 394,765 (49.3%)\n",
      "\n",
      "Total records: 800,000\n",
      "Total assigned: 963,107\n",
      "Records per segment on average: 160,517.8\n",
      "Predictions exported to predicted_premiums.csv.\n"
     ]
    }
   ],
   "source": [
    "def segment_test_data(df):\n",
    "\n",
    "    segments = segment_data(df)\n",
    "\n",
    "    # Apply the boolean mask to the DataFrame and return actual data segments\n",
    "    for key, mask in segments.items():\n",
    "        segments[key] = df[mask]\n",
    "\n",
    "    return segments\n",
    "\n",
    "def predict_and_export(test_df, model, output_file='predicted_premiums.csv'):\n",
    "    test_df_processed, test_ids = preprocess_data(test_df)\n",
    "    predictions = []\n",
    "\n",
    "    # Generate segments for the test data using the standalone function\n",
    "    segments = segment_test_data(test_df_processed)\n",
    "\n",
    "    for segment_name, test_segment in segments.items():\n",
    "        # Ensure there are indices in this segment\n",
    "        if not test_segment.empty:\n",
    "            test_segment_ids = test_ids[test_segment.index]\n",
    "\n",
    "            # Predict the segment\n",
    "            try:\n",
    "                predicted_values = model.get_segment_predictions(segment_name, test_segment)\n",
    "                # Collect ID and corresponding predictions\n",
    "                predictions.extend(zip(test_segment_ids, predicted_values))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment {segment_name}: {e}\")\n",
    "\n",
    "    # Convert predictions to DataFrame\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['id', 'Premium Amount'])\n",
    "\n",
    "    # Average the premium amounts for IDs with multiple entries\n",
    "    predictions_df = predictions_df.groupby('id')['Premium Amount'].mean().reset_index()\n",
    "\n",
    "    # Save the averaged results to CSV\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions exported to {output_file}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the test dataset\n",
    "    test = pd.read_csv('test.csv')\n",
    "\n",
    "    # Assuming the model is already instantiated and available as `insurance_model`\n",
    "    predict_and_export(test, insurance_model, 'predicted_premiums.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
