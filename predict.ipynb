{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN values before imputation:\n",
      "Age                      18705\n",
      "Gender                       0\n",
      "Annual Income            44949\n",
      "Marital Status           18529\n",
      "Number of Dependents    109672\n",
      "Education Level              0\n",
      "Occupation              358075\n",
      "Health Score             74076\n",
      "Location                     0\n",
      "Policy Type                  0\n",
      "Previous Claims         364029\n",
      "Vehicle Age                  6\n",
      "Credit Score            137882\n",
      "Insurance Duration           1\n",
      "Customer Feedback        77824\n",
      "Smoking Status               0\n",
      "Exercise Frequency           0\n",
      "Property Type                0\n",
      "Premium Amount               0\n",
      "dtype: int64\n",
      "\n",
      "NaN values after imputation:\n",
      "Age                     0\n",
      "Gender                  0\n",
      "Annual Income           0\n",
      "Marital Status          0\n",
      "Number of Dependents    0\n",
      "Education Level         0\n",
      "Occupation              0\n",
      "Health Score            0\n",
      "Location                0\n",
      "Policy Type             0\n",
      "Previous Claims         0\n",
      "Vehicle Age             0\n",
      "Credit Score            0\n",
      "Insurance Duration      0\n",
      "Customer Feedback       0\n",
      "Smoking Status          0\n",
      "Exercise Frequency      0\n",
      "Property Type           0\n",
      "Premium Amount          0\n",
      "dtype: int64\n",
      "\n",
      "Segment Distribution:\n",
      "High_Value_Property: 55,676 (4.6%)\n",
      "Low_Risk_Premium: 140,106 (11.7%)\n",
      "Healthy_Professional: 77,964 (6.5%)\n",
      "Family_Premium: 131,515 (11.0%)\n",
      "Senior_Premium: 50,316 (4.2%)\n",
      "Basic_Coverage: 267,295 (22.3%)\n",
      "Default_Segment: 623,920 (52.0%)\n",
      "\n",
      "Total records: 1,200,000\n",
      "Total assigned: 1,346,792\n",
      "Records per segment on average: 192,398.9\n",
      "\n",
      "Processing High_Value_Property segment...\n",
      "\n",
      "Segment Length 55676...\n",
      "Train R2: 0.1445\n",
      "Test R2: 0.0610\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 664.57\n",
      "Median Absolute Error: 500.68\n",
      "Mean % Error: 330.83%\n",
      "RMSE: 889.10\n",
      "CV Mean R2: 0.0679 (+/- 0.0129)\n",
      "\n",
      "Processing Low_Risk_Premium segment...\n",
      "\n",
      "Segment Length 140106...\n",
      "Train R2: 0.1121\n",
      "Test R2: 0.0614\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 654.93\n",
      "Median Absolute Error: 502.10\n",
      "Mean % Error: 305.96%\n",
      "RMSE: 876.20\n",
      "CV Mean R2: 0.0639 (+/- 0.0036)\n",
      "\n",
      "Processing Healthy_Professional segment...\n",
      "\n",
      "Segment Length 77964...\n",
      "Train R2: 0.1189\n",
      "Test R2: 0.0474\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 662.40\n",
      "Median Absolute Error: 519.32\n",
      "Mean % Error: 299.71%\n",
      "RMSE: 874.98\n",
      "CV Mean R2: 0.0504 (+/- 0.0059)\n",
      "\n",
      "Processing Family_Premium segment...\n",
      "\n",
      "Segment Length 131515...\n",
      "Train R2: 0.1007\n",
      "Test R2: 0.0499\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 656.88\n",
      "Median Absolute Error: 514.67\n",
      "Mean % Error: 301.87%\n",
      "RMSE: 866.32\n",
      "CV Mean R2: 0.0510 (+/- 0.0104)\n",
      "\n",
      "Processing Senior_Premium segment...\n",
      "\n",
      "Segment Length 50316...\n",
      "Train R2: 0.1291\n",
      "Test R2: 0.0477\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 646.55\n",
      "Median Absolute Error: 498.40\n",
      "Mean % Error: 310.10%\n",
      "RMSE: 858.63\n",
      "CV Mean R2: 0.0472 (+/- 0.0058)\n",
      "\n",
      "Processing Basic_Coverage segment...\n",
      "\n",
      "Segment Length 267295...\n",
      "Train R2: 0.0547\n",
      "Test R2: 0.0238\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 665.57\n",
      "Median Absolute Error: 530.08\n",
      "Mean % Error: 329.06%\n",
      "RMSE: 861.56\n",
      "CV Mean R2: 0.0228 (+/- 0.0018)\n",
      "\n",
      "Processing Default_Segment segment...\n",
      "\n",
      "Segment Length 623920...\n",
      "Train R2: 0.0565\n",
      "Test R2: 0.0373\n",
      "\n",
      "Prediction Accuracy:\n",
      "Mean Absolute Error: 636.87\n",
      "Median Absolute Error: 498.50\n",
      "Mean % Error: 292.90%\n",
      "RMSE: 840.10\n",
      "CV Mean R2: 0.0383 (+/- 0.0032)\n",
      "\n",
      "Segment Performance Summary:\n",
      "                      segment_size  train_r2   test_r2  cv_mean_r2  cv_std_r2  \\\n",
      "Low_Risk_Premium            623920  0.112109  0.061366    0.063889   0.001795   \n",
      "High_Value_Property         623920  0.144481  0.061010    0.067931   0.006458   \n",
      "Family_Premium              623920  0.100723  0.049875    0.050980   0.005211   \n",
      "Senior_Premium              623920  0.129144  0.047710    0.047220   0.002889   \n",
      "Healthy_Professional        623920  0.118863  0.047401    0.050425   0.002926   \n",
      "Default_Segment             623920  0.056529  0.037307    0.038346   0.001599   \n",
      "Basic_Coverage              623920  0.054698  0.023826    0.022808   0.000891   \n",
      "\n",
      "                             mae        mape  \n",
      "Low_Risk_Premium      654.933028  305.963951  \n",
      "High_Value_Property   664.565742  330.826661  \n",
      "Family_Premium        656.884562  301.867502  \n",
      "Senior_Premium        646.552532  310.099950  \n",
      "Healthy_Professional  662.399212  299.708326  \n",
      "Default_Segment       636.868375  292.896580  \n",
      "Basic_Coverage        665.565063  329.057574  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.impute import KNNImputer\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from preprocess import preprocess_insurance_data\n",
    "\n",
    "def define_segments(df):\n",
    "\n",
    "    segments = {\n",
    "        'High_Value_Property': (\n",
    "            (df['Property Type'].isin(['House', 'Condo'])) &\n",
    "            (df['Annual Income'] >= df['Annual Income'].quantile(0.55)) &\n",
    "            ((df['Policy Type'] == 'Premium') | \n",
    "            (df['Policy Type'] == 'Standard')) &\n",
    "            (df['Credit Score'] > df['Credit Score'].quantile(0.45))\n",
    "        ),\n",
    "        \n",
    "        'Low_Risk_Premium': (\n",
    "            (df['Credit Score'] > df['Credit Score'].quantile(0.5)) &\n",
    "            (df['Health Score'] > df['Health Score'].quantile(0.5)) &\n",
    "            (df['Insurance Duration'] > 1) &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.4))\n",
    "        ),\n",
    "        \n",
    "        'Healthy_Professional': (\n",
    "            ((df['Age'] <= df['Age'].quantile(0.4)) |\n",
    "            (df['Exercise Frequency'].isin(['Daily', 'Weekly']))) &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.45)) &\n",
    "            ((df['Policy Type'] == 'Premium') | (df['Policy Type'] == 'Standard')) &\n",
    "            (df['Health Score'] > df['Health Score'].quantile(0.5))\n",
    "        ),\n",
    "        \n",
    "        'Family_Premium': (\n",
    "            (df['Number of Dependents'] >= 1) &\n",
    "            (df['Location'].isin(['Suburban', 'Rural'])) &\n",
    "            (df['Marital Status'] == 'Married') &\n",
    "            (df['Annual Income'] > df['Annual Income'].quantile(0.4)) &\n",
    "            (df['Insurance Duration'] > 0)\n",
    "        ),\n",
    "        \n",
    "        'Senior_Premium': (\n",
    "            (df['Age'] >= df['Age'].quantile(0.55)) &\n",
    "            (df['Insurance Duration'] > df['Insurance Duration'].quantile(0.45)) &\n",
    "            (df['Credit Score'] > df['Credit Score'].quantile(0.4)) &\n",
    "            ((df['Policy Type'] == 'Premium') | (df['Policy Type'] == 'Standard'))\n",
    "        ),\n",
    "        \n",
    "        'Basic_Coverage': (\n",
    "            ((df['Annual Income'] <= df['Annual Income'].quantile(0.35)) |\n",
    "            (df['Previous Claims'] >= 2) |\n",
    "            (df['Credit Score'] < df['Credit Score'].quantile(0.35))) &\n",
    "            (df['Policy Type'] == 'Basic')\n",
    "        )\n",
    "    }\n",
    "\n",
    "    return segments\n",
    "\n",
    "def define_model():\n",
    "\n",
    "    # Define model configurations\n",
    "    model = {\n",
    "        'default': {\n",
    "            'model': RandomForestRegressor(\n",
    "                n_estimators=120,\n",
    "                max_depth=10,\n",
    "                min_samples_leaf=25,\n",
    "                n_jobs=-1,\n",
    "                random_state=42\n",
    "            ),\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return model\n",
    "\n",
    "def segment_data(df):\n",
    "\n",
    "    segments = define_segments(df)\n",
    "\n",
    "    # Create a mask for all data assigned to a segment\n",
    "    assigned_mask = np.zeros(len(df), dtype=bool)\n",
    "    for mask in segments.values():\n",
    "        assigned_mask |= mask\n",
    "\n",
    "    # Create a default segment for unassigned data\n",
    "    segments['Default_Segment'] = ~assigned_mask\n",
    "\n",
    "    # Print distribution for debugging\n",
    "    total_records = len(df)\n",
    "    print(\"\\nSegment Distribution:\")\n",
    "    total_assigned = 0\n",
    "    for name, mask in segments.items():\n",
    "        segment_size = mask.sum()\n",
    "        total_assigned += segment_size\n",
    "        percentage = (segment_size / total_records) * 100\n",
    "        print(f\"{name}: {segment_size:,} ({percentage:.1f}%)\")\n",
    "\n",
    "    # Additional debug info\n",
    "    print(f\"\\nTotal records: {total_records:,}\")\n",
    "    print(f\"Total assigned: {total_assigned:,}\")\n",
    "    print(f\"Records per segment on average: {total_assigned/len(segments):,.1f}\")\n",
    "\n",
    "    return segments\n",
    "\n",
    "class InsuranceSegmentModel:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"Initialize the model with a DataFrame\"\"\"\n",
    "        self.df = df\n",
    "        self.processed_df = None\n",
    "        self.segment_results = {}\n",
    "        self.cv_results = {}\n",
    "\n",
    "        # Create standard category mappings at initialization\n",
    "        self.categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        if 'Premium Amount' in self.categorical_features:\n",
    "            self.categorical_features.remove('Premium Amount')\n",
    "            \n",
    "        self.category_mappings = {\n",
    "            col: sorted(df[col].unique()) for col in self.categorical_features\n",
    "        }\n",
    "\n",
    "        # Segment data\n",
    "        self.segments = segment_data(df)\n",
    "\n",
    "        # Define model\n",
    "        self.segment_configs = define_model()\n",
    "\n",
    "    def create_segment_pipeline(self, segment_name):\n",
    "        \"\"\"Creates a pipeline specific to a segment\"\"\"\n",
    "        config = self.segment_configs.get(segment_name, self.segment_configs['default'])\n",
    "        \n",
    "        # Define feature groups\n",
    "        numeric_features = self.df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "        if 'Premium Amount' in numeric_features:\n",
    "            numeric_features.remove('Premium Amount')\n",
    "                \n",
    "        # Only need encoder for categorical features\n",
    "        categorical_transformer = OneHotEncoder(\n",
    "            categories=[self.category_mappings[col] for col in self.categorical_features],\n",
    "            sparse_output=False,\n",
    "            handle_unknown='ignore'\n",
    "        )\n",
    "        \n",
    "        # Create preprocessor - numeric features pass through unchanged\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', 'passthrough', numeric_features),\n",
    "                ('cat', categorical_transformer, self.categorical_features)\n",
    "            ],\n",
    "            sparse_threshold=0\n",
    "        )\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('regressor', config['model'])\n",
    "        ])\n",
    "        \n",
    "        return pipeline\n",
    "        \n",
    "    def evaluate_predictions(self, y_true, y_pred):\n",
    "        \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "        return {\n",
    "            'r2_score': r2_score(y_true, y_pred),\n",
    "            'mae': mean_absolute_error(y_true, y_pred),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "            'mape': np.mean(np.abs((y_true - y_pred) / y_true)) * 100,\n",
    "            'median_ae': np.median(np.abs(y_true - y_pred))\n",
    "        }\n",
    "    \n",
    "    def train_segment_model(self, X_seg, y_seg, segment_name):\n",
    "        \"\"\"Trains and evaluates a model for a specific customer segment\"\"\"\n",
    "        # Create pipeline\n",
    "        pipeline = self.create_segment_pipeline(segment_name)\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X_seg, y_seg, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        train_predictions = pipeline.predict(X_train)\n",
    "        test_predictions = pipeline.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        train_metrics = self.evaluate_predictions(y_train, train_predictions)\n",
    "        test_metrics = self.evaluate_predictions(y_test, test_predictions)\n",
    "        \n",
    "        # Perform cross-validation\n",
    "        cv_scores = cross_val_score(\n",
    "            pipeline, X_seg, y_seg,\n",
    "            cv=5,\n",
    "            scoring=make_scorer(r2_score),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        results = {\n",
    "            'model': pipeline,\n",
    "            'train_metrics': train_metrics,\n",
    "            'test_metrics': test_metrics,\n",
    "            'cv_scores': cv_scores,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'test_data': (X_test, y_test)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def analyze_feature_importance(self, segment_name):\n",
    "        \"\"\"Analyzes feature importance for a specific segment\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            return None\n",
    "        \n",
    "        results = self.segment_results[segment_name]\n",
    "        model = results['model']\n",
    "        \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = []\n",
    "        \n",
    "        # Get numeric feature names\n",
    "        num_features = model.named_steps['preprocessor'].transformers_[0][2]\n",
    "        feature_names.extend(num_features)\n",
    "        \n",
    "        # Get encoded categorical feature names\n",
    "        cat_features = model.named_steps['preprocessor'].transformers_[1][2]\n",
    "        if len(cat_features) > 0:\n",
    "            encoder = model.named_steps['preprocessor'].named_transformers_['cat']\n",
    "            if hasattr(encoder, 'get_feature_names_out'):\n",
    "                encoded_features = encoder.get_feature_names_out(cat_features)\n",
    "                feature_names.extend(encoded_features)\n",
    "        \n",
    "        # Get feature importances\n",
    "        if hasattr(model.named_steps['regressor'], 'feature_importances_'):\n",
    "            importances = model.named_steps['regressor'].feature_importances_\n",
    "        else:\n",
    "            # For stacking regressor, use the average of base estimators\n",
    "            importances = np.mean([\n",
    "                est.feature_importances_ \n",
    "                for name, est in model.named_steps['regressor'].estimators_\n",
    "                if hasattr(est, 'feature_importances_')\n",
    "            ], axis=0)\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    def train_all_segments(self):\n",
    "        \"\"\"Trains models for all segments and generates performance summary\"\"\"\n",
    "        # Define feature and target columns\n",
    "        feature_cols = [col for col in self.df.columns if col != 'Premium Amount']\n",
    "        target_col = 'Premium Amount'\n",
    "        \n",
    "        # Use the original dataframe directly\n",
    "        self.processed_df = self.df.copy()\n",
    "        \n",
    "        # Train models for each segment\n",
    "        for name, mask in self.segments.items():\n",
    "            print(f\"\\nProcessing {name} segment...\")\n",
    "            X_seg = self.processed_df[feature_cols][mask]\n",
    "            y_seg = self.processed_df[target_col][mask]\n",
    "            print(f\"\\nSegment Length {len(X_seg)}...\")\n",
    "\n",
    "            if len(X_seg) >= 100:\n",
    "                results = self.train_segment_model(X_seg, y_seg, name)\n",
    "                self.segment_results[name] = results\n",
    "                \n",
    "                print(f\"Train R2: {results['train_metrics']['r2_score']:.4f}\")\n",
    "                print(f\"Test R2: {results['test_metrics']['r2_score']:.4f}\")\n",
    "                print(\"\\nPrediction Accuracy:\")\n",
    "                print(f\"Mean Absolute Error: {results['test_metrics']['mae']:.2f}\")\n",
    "                print(f\"Median Absolute Error: {results['test_metrics']['median_ae']:.2f}\")\n",
    "                print(f\"Mean % Error: {results['test_metrics']['mape']:.2f}%\")\n",
    "                print(f\"RMSE: {results['test_metrics']['rmse']:.2f}\")\n",
    "                print(f\"CV Mean R2: {results['cv_mean']:.4f} (+/- {results['cv_std']*2:.4f})\")\n",
    "        \n",
    "        # Create performance summary\n",
    "        performance_df = pd.DataFrame.from_dict(\n",
    "            {name: {\n",
    "                'segment_size': len(self.processed_df[mask]),\n",
    "                'train_r2': results['train_metrics']['r2_score'],\n",
    "                'test_r2': results['test_metrics']['r2_score'],\n",
    "                'cv_mean_r2': results['cv_mean'],\n",
    "                'cv_std_r2': results['cv_std'],\n",
    "                'mae': results['test_metrics']['mae'],\n",
    "                'mape': results['test_metrics']['mape']\n",
    "            } for name, results in self.segment_results.items()},\n",
    "            orient='index'\n",
    "        )\n",
    "        \n",
    "        print(\"\\nSegment Performance Summary:\")\n",
    "        print(performance_df.sort_values('test_r2', ascending=False))\n",
    "                \n",
    "        return performance_df\n",
    "    \n",
    "    def get_segment_predictions(self, segment_name, X_new):\n",
    "        \"\"\"Get predictions for new data using a trained segment model\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            raise ValueError(f\"No trained model found for segment: {segment_name}\")\n",
    "        \n",
    "        model = self.segment_results[segment_name]['model']\n",
    "        return model.predict(X_new)\n",
    "    \n",
    "    def get_feature_importance(self, segment_name):\n",
    "        \"\"\"Get feature importance analysis for a specific segment\"\"\"\n",
    "        return self.analyze_feature_importance(segment_name)\n",
    "    \n",
    "    def get_segment_metrics(self, segment_name):\n",
    "        \"\"\"Get detailed performance metrics for a specific segment\"\"\"\n",
    "        if segment_name not in self.segment_results:\n",
    "            raise ValueError(f\"No results found for segment: {segment_name}\")\n",
    "        \n",
    "        results = self.segment_results[segment_name]\n",
    "        return {\n",
    "            'train_metrics': results['train_metrics'],\n",
    "            'test_metrics': results['test_metrics'],\n",
    "            'cv_scores': results['cv_scores'],\n",
    "            'cv_mean': results['cv_mean'],\n",
    "            'cv_std': results['cv_std']\n",
    "        }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train = pd.read_csv('train.csv')\n",
    "    processed_df, _ = preprocess_insurance_data(train)\n",
    "    insurance_model = InsuranceSegmentModel(processed_df)\n",
    "    performance_summary = insurance_model.train_all_segments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NaN values before imputation:\n",
      "Age                      12489\n",
      "Gender                       0\n",
      "Annual Income            29860\n",
      "Marital Status           12336\n",
      "Number of Dependents     73130\n",
      "Education Level              0\n",
      "Occupation              239125\n",
      "Health Score             49449\n",
      "Location                     0\n",
      "Policy Type                  0\n",
      "Previous Claims         242802\n",
      "Vehicle Age                  3\n",
      "Credit Score             91451\n",
      "Insurance Duration           2\n",
      "Customer Feedback        52276\n",
      "Smoking Status               0\n",
      "Exercise Frequency           0\n",
      "Property Type                0\n",
      "dtype: int64\n",
      "\n",
      "NaN values after imputation:\n",
      "Age                     0\n",
      "Gender                  0\n",
      "Annual Income           0\n",
      "Marital Status          0\n",
      "Number of Dependents    0\n",
      "Education Level         0\n",
      "Occupation              0\n",
      "Health Score            0\n",
      "Location                0\n",
      "Policy Type             0\n",
      "Previous Claims         0\n",
      "Vehicle Age             0\n",
      "Credit Score            0\n",
      "Insurance Duration      0\n",
      "Customer Feedback       0\n",
      "Smoking Status          0\n",
      "Exercise Frequency      0\n",
      "Property Type           0\n",
      "dtype: int64\n",
      "\n",
      "Segment Distribution:\n",
      "High_Value_Property: 36,755 (4.6%)\n",
      "Low_Risk_Premium: 97,206 (12.2%)\n",
      "Healthy_Professional: 52,090 (6.5%)\n",
      "Family_Premium: 86,204 (10.8%)\n",
      "Senior_Premium: 33,290 (4.2%)\n",
      "Basic_Coverage: 178,888 (22.4%)\n",
      "Default_Segment: 411,271 (51.4%)\n",
      "\n",
      "Total records: 800,000\n",
      "Total assigned: 895,704\n",
      "Records per segment on average: 127,957.7\n",
      "Predictions exported to predicted_premiums.csv.\n"
     ]
    }
   ],
   "source": [
    "def segment_test_data(df):\n",
    "\n",
    "    segments = segment_data(df)\n",
    "\n",
    "    # Apply the boolean mask to the DataFrame and return actual data segments\n",
    "    for key, mask in segments.items():\n",
    "        segments[key] = df[mask]\n",
    "\n",
    "    return segments\n",
    "\n",
    "def predict_and_export(test_df, model, output_file='predicted_premiums.csv'):\n",
    "    test_df_processed, test_ids = preprocess_insurance_data(test_df)\n",
    "    predictions = []\n",
    "\n",
    "    # Generate segments for the test data using the standalone function\n",
    "    segments = segment_test_data(test_df_processed)\n",
    "\n",
    "    for segment_name, test_segment in segments.items():\n",
    "        # Ensure there are indices in this segment\n",
    "        if not test_segment.empty:\n",
    "            test_segment_ids = test_ids[test_segment.index]\n",
    "\n",
    "            # Predict the segment\n",
    "            try:\n",
    "                predicted_values = model.get_segment_predictions(segment_name, test_segment)\n",
    "                # Collect ID and corresponding predictions\n",
    "                predictions.extend(zip(test_segment_ids, predicted_values))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing segment {segment_name}: {e}\")\n",
    "\n",
    "    # Convert predictions to DataFrame\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['id', 'Premium Amount'])\n",
    "\n",
    "    # Average the premium amounts for IDs with multiple entries\n",
    "    predictions_df = predictions_df.groupby('id')['Premium Amount'].mean().reset_index()\n",
    "\n",
    "    # Save the averaged results to CSV\n",
    "    predictions_df.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions exported to {output_file}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the test dataset\n",
    "    test = pd.read_csv('test.csv')\n",
    "\n",
    "    # Assuming the model is already instantiated and available as `insurance_model`\n",
    "    predict_and_export(test, insurance_model, 'predicted_premiums.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
